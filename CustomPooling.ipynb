{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom pooling layers"
      ],
      "metadata": {
        "id": "I2T7uQ629esG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBT97r3X9WVK",
        "outputId": "18f36522-1787-4247-c994-2ad5ab0c81fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "import timm"
      ],
      "metadata": {
        "id": "OXvutGBI95rS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GeM layer\n",
        "Generalized Mean Pooling and Attention Pooling are obtained from this notebook[kaggle_rsna_abdominal_trauma](https://github.com/TheoViel/kaggle_rsna_abdominal_trauma/blob/cleaning/src/model_zoo/layers.py)"
      ],
      "metadata": {
        "id": "x1GFE1iN-OO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gem(x, p=3, eps=1e-4):\n",
        "    \"\"\"\n",
        "    Apply a Generalized Mean Pooling (GeM) as a tensor\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): Input a tensor of shape (batch_size, channels, height, width)\n",
        "        p (float): The p-value for the generalized mean. Default is 3\n",
        "        eps (float): A small constant added to the denominator to prevent division by zero. Default is 1e-3\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: GeM-pooled representation of the input tensor\n",
        "    \"\"\"\n",
        "    return F.avg_pool2d(x.clamp(min=eps), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
        "\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    \"\"\"\n",
        "    Generalized Mean Pooling (GeM) layer for global average pooling\n",
        "    Attributes:\n",
        "        p (float or torch.Tensor): The p-value for the generalized mean\n",
        "        eps (float): A small constant added to the denominator to prevent division by zero\n",
        "    \"\"\"\n",
        "    def __init__(self, p=3, eps=1e-6, p_trainable=False):\n",
        "        \"\"\"\n",
        "        Initialize the GeM layer\n",
        "        Args:\n",
        "            p (float or torch.Tensor): The p-value for the generalized mean\n",
        "            eps (float, optional): Eps to prevent division by zero. Defaults to 1e-6\n",
        "            p_trainable (bool, optional): Whether p is trainable. Defaults to False\n",
        "        \"\"\"\n",
        "        super(GeM, self).__init__()\n",
        "        if p_trainable:\n",
        "            self.p = Parameter(torch.ones(1) * p)\n",
        "        else:\n",
        "            self.p = p\n",
        "        self.eps = eps\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform the GeM pooling operation on the input tensor\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width)\n",
        "        Returns:\n",
        "            torch.Tensor: GeM-pooled representation of the input tensor\n",
        "        \"\"\"\n",
        "        ret = gem(x, p=self.p, eps=self.eps)\n",
        "        return ret\n",
        "\n",
        "\n",
        "xx = torch.rand(8, 3, 224, 224)\n",
        "g = GeM()\n",
        "g(xx).shape\n",
        "# yy = gem(xx)\n",
        "# yy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNZI-Whn-IZH",
        "outputId": "9031b245-f5ae-4811-afeb-ea7a30f62dc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 3, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Pooling"
      ],
      "metadata": {
        "id": "deLpKNY1BNGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention module for sequence data\n",
        "\n",
        "    Attributes:\n",
        "        Hidden dim (int): The dimension of the input sequence\n",
        "        Attention dim (int): The dimension of the attention layer\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim, attention_dim=None):\n",
        "        \"\"\"\n",
        "        Constructor\n",
        "\n",
        "        Args:\n",
        "            hidden_dim (int): The dimension of the input sequence\n",
        "            attention dim (int, optional): The dimension of the attention layer\n",
        "                Defaults to None, in which case it's set to `hidden dim`\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.attention_dim = attention_dim\n",
        "        if self.attention_dim is None:\n",
        "            self.attention_dim = self.hidden_dim\n",
        "        # W * x + b\n",
        "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
        "        # v.T\n",
        "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the attention mechanism\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input sequence data of shape (batch_size, seq_len, input_dim)\n",
        "        Returns:\n",
        "            torch.Tensor: Attention-weighted representation of the input sequence\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        H = torch.tanh(self.proj_w(x))\n",
        "        att_scores = torch.softmax(self.proj_v(H), axis=1)\n",
        "        attn_x = (x * att_scores).sum(1)\n",
        "        return attn_x\n",
        "\n",
        "x = torch.randn(8, 384, 224)\n",
        "attn = Attention(hidden_dim=224)\n",
        "attn(x).shape\n",
        "\n",
        "# hidden dim == input_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVaLOURP-Nn8",
        "outputId": "048237e2-73a3-4397-ff61-be85fc87a615"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample model"
      ],
      "metadata": {
        "id": "0GuHDKHcEUBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimmModel(nn.Module):\n",
        "    def __init__(self, backbone, pretrained=False, use_gem=False, pooling=\"mean\"):\n",
        "        super(TimmModel, self).__init__()\n",
        "        self.encoder = timm.create_model(backbone, pretrained=pretrained, num_classes=0)\n",
        "        self.nb_fts = self.encoder.num_features\n",
        "        self.use_gem = use_gem\n",
        "        self.pooling = pooling\n",
        "\n",
        "        if self.use_gem:\n",
        "            self.global_pool = GeM(p_trainable=False)\n",
        "        else:\n",
        "            self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        if self.pooling == \"lstm\":\n",
        "            self.lstm = nn.LSTM(\n",
        "                self.nb_fts, self.nb_fts // 4, batch_first=True, bidirectional=True\n",
        "            )\n",
        "        elif self.pooling == \"lstm_att\":\n",
        "            self.lstm = nn.LSTM(\n",
        "                self.nb_fts, self.nb_fts // 2, batch_first=True, bidirectional=True\n",
        "            )\n",
        "            self.att = Attention(self.nb_fts)\n",
        "\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        \"\"\"\n",
        "        Extract features from input images\n",
        "        Args:\n",
        "            x (torch.Tensor): Input images of shape [batch_size x channels x H x W]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Extracted features of shape [batch_size x num_features]\n",
        "        \"\"\"\n",
        "        fts = self.encoder.forward_features(x)\n",
        "\n",
        "        if self.use_gem and len(fts.size()) == 4:\n",
        "            fts = self.global_pool(fts)[:,:,0,0]\n",
        "        else:\n",
        "            while len(fts.size()) > 2:\n",
        "                fts = fts.mean(-1)\n",
        "\n",
        "        return fts\n",
        "\n",
        "\n",
        "    def forward_head(self, x):\n",
        "        if self.pooling == \"mean\":\n",
        "            return x.mean(1)\n",
        "        elif self.pooling == \"max\":\n",
        "            return x.amax(1)\n",
        "        elif self.pooling == \"lstm\":\n",
        "            x, _ = self.lstm(x)\n",
        "            mean = x.mean(1)\n",
        "            max_ = x.amax(1)\n",
        "            x = torch.cat([mean, max_], -1)\n",
        "        elif self.pooling == \"lstm_att\":\n",
        "            x, _ = self.lstm(x)\n",
        "            x = self.att(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.extract_features(x)\n",
        "        bs, _ = x.size()\n",
        "        x = x.view(bs, -1, self.nb_fts)\n",
        "        x = self.forward_head(x)\n",
        "        return x\n",
        "\n",
        "model = TimmModel(backbone='resnet18', use_gem=True, pooling=\"lstm_att\")\n",
        "model(xx).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St7cnf5yC_JN",
        "outputId": "b36be6e1-ca92-4d1f-f4eb-794182d9f993"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0kX0dTmEdWH"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDrzy3neMT8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}